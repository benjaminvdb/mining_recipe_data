\section{Methodology}
\label{sec:methodology}

This section explains the methods and techniques used in the analysis of the datasets.
The two datasets, the ingredient itemsets and user ratings, contain different types of data.
Therefore, different techniques are required in order to analyze them.
Looking at the ingredient itemsets, here we are particularly interested in combinations of ingredients that frequently occur in the data.
The rating data can be seen as a sample of a much larger dataset that contains preferences of a set of people towards a set of recipes.
Most of the ratings are however unknown and the main objective here is to approximate these ratings such that they can be studied in relation to the ingredient sets.


%============================================================


\subsection{Frequent Itemsets and Association Rules}
\label{subsec:frequent_itemsets}

The ingredient itemsets can be studied using techniques from \emph{Association Rule Mining}, which creates a depedency model from discrete data \citep{Agrawal1993}.
It was originally used to mine shopping baskets for frequently occurring patterns, information that can be used for product placement in stores and other marketing purposes.
The problem is formally defined as:

\begin{definition}[Association Rule Mining]
	Let $I = \{i_1, i_2, \dots, i_n\}$ be a set of $n$ binary attributes called items. Each transaction in $\mathcal{D}=\{t_1, t_2, \dots, t_m$ be a set of transaction called the \emph{database}. Each transaction in $\mathcal{D}$ has a unique transaction ID and contains a subset of the item in $I$. A \emph{rule} is defined as an implication of the form $X \rightarrow Y$ where $X,Y \subseteq I$ and $X \cap Y=\empty$. The sets of item (for short \emph{itemsets}) $X$ and $Y$ are called \emph{antecedent} (left-hand-side or LHS) and \emph{consequent} (right-hand-side or RHS) of the rule.
\end{definition}

Since the number of possible combinations of ingredients, and therefore rules, is extremely large, a number of \emph{interestingness measures} can be used to narrow the search down.
One observation is that association rules that only infrequently occur are not interesting.
Another is that the number of transaction for which an association rule holds, i.e., $X \rightarrow Y$, should be sufficiently large.
These two observations are captured in the following measures of interestingness:

\begin{definition}[Support]
	The \emph{support} of a given itemset $X$, with respect to a database $\mathcal{D}$, is defined as the proportion of transactions in the database which contains the itemset $X$, i.e.:
	\begin{equation*}
		\mathrm{supp}(X)=|\{t \mid t\in\mathcal{D}, X \subseteq t\}|
	\end{equation*}
	\noindent with $|\cdot|$ denoting the cardinality of a set.
\end{definition}

By setting a threshold on the support of an itemset, it is possible to exclude sets with a low threshold when searching the database, effectively pruning the search space.

\begin{definition}[Confidence]
	The \emph{confidence} value of a rule, with respect to a database $\mathcal{D}$, is the proportion of the transaction that contain both itemsets $X$ and $Y$, i.e,:
	\begin{equation*}
		\mathrm{conf}(X \rightarrow Y)=\frac{\mathrm{supp}(X \cup Y)}{\mathrm{supp}(X)}
	\end{equation*}
	\noindent $\mathrm{conf}(X \rightarrow Y)$ is defined to be $0$ for $\mathrm{supp}(X)=0$.
\end{definition}

The interpretation of the confidence value is that it is an estimate of the probability $P(Y \mid X)$, the probability of finding the antecedent of the rule in transactions under the condition that these transactions also contain the precedent.
The confidence value can be used to prune the search space from association rules that infrequently hold.
Using the definition of support, we can formally define a frequent dataset as follows:

\begin{definition}[Frequent Itemset]
	A \emph{frequent itemset} is a set $X$ for which $\mathrm{supp}(X)>t$, where $0 \leq t \leq 1$ is some support threshold value.
\end{definition}

If the support threshold is set to a low value, a lot of maximal frequent itemsets are often found.
Because of that, computing association rules from these frequent itemsets might still prove intractable.
The definition of \emph{support}, however, defines that subsets of frequent itemsets also have to be frequent \citep{Hahsler2007}.
This allows us to mine only the \emph{maximal informative itemsets}, since their union contains all frequent itemsets.

\begin{definition}[Maximal Frequent Itemset]
	A \emph{maximal frequent itemset} $X$ is a frequent itemset that is not a proper subset of another frequent itemset.
\end{definition}

There exist a number of association rule mining algorithms, but for this research, the Apriori algorithm \citep{Agrawal1993} will be used.
Apriori utilizes the the fact that all subsets of a frequent itemset are also frequent itemsets.
The high-level pseudocode of the algorithm is given in \cref{alg:apriori}, with most of the details left out, which can be found in the work of \cite{Agrawal1993}.
The algorithm uses a bottom-up approach that constructs larger and larger frequent itemsets by combining frequent itemsets found in earlier iterations into a \emph{candidate set} (line $7$) and then testing for the minimal support (line $8$).
The stopping criterion is that the frequent itemset of the previous round should not be empty, which occurs when no itemsets were found that have a sufficiently high support.
Computing frequent itemsets can be performed efficiently, because the support for subsets of new candidates have been computed in a previous iteration.

\begin{algorithm}[htbp]
	\caption{Computes maximal frequent itemsets}
	\label{alg:apriori}
	\input{algorithms/apriori}
\end{algorithm}

Association rules can now be computed from the set of maximal frequent itemsets $F$ by generating from each element all possible rules and computing their individual confidence scores.
A commonly used measure for interestingness of association rules is \emph{lift}.

\begin{equation}
	\mathrm{lift}(X \rightarrow Y)=\frac{\mathrm{supp}(X \cup U)}{\mathrm{supp}(X) \times \mathrm{supp}(Y)}
\end{equation}

It provides a measure of dependence between the precedent and antecedent.
They are completely independent if $\mathrm{lift}(X \rightarrow Y)=1$, while they are dependent if $\mathrm{lift}(X \rightarrow Y)>1$.


%============================================================


\subsection{Recommender Systems}
\label{subsec:recommender_systems}

The intended purpose of this research is to suggest recipes and ingredients to users.
A lot of research has been done on \emph{Recommender Systems} that solve this recommendation problem \citep{Ricci2010}.

\begin{definition}[Recommendation Problem]
	Given database $\mathcal{D} \in U \times M \times S$ tuples of ratings $s\in S$ that users $u \in U$ have given to items $m \in M$, and an \emph{active user} $u_a \in U$, return a list $(m_1, m_2, \dots, m_N)$ of items not in $\mathcal{D}$.
\end{definition}

This problem can be approached in several ways, but two are the most common:

\begin{enumerate}
	\item The ratings for user-item pairs not in the database can be approximated from the dataset, after which a top-$N$ ranking for the active user is computed.
	\item A top-$N$ list of recommendations can be presented without computing all ratings first (which can be computationally expensive).
\end{enumerate}

Transforming the database into a sparse matrix $R$ with $R_{ij}=0$ if user $u_i$ did not rate $m_j$, with usually a low density (see \cref{subsubsec:user_ratings}).
The first method fills in these missing values by collecting preferences of many users in collaboration.
This method is also called \emph{Collaborative Filtering} (CF), a general term for a range of series based on the idea of collaboration.
Several techniques exist of which a few will be used and compared.

For the second method, association rules can be utilized, which result in a descriptive way of recommending items.
The database is mined for rules in the form of ``if a user likes items $m_p$ and $m_q$ then he/she also likes item $m_r$''.
These patterns are then searched for the user's rated item, after which a recommendation can be presented.


%------------------------------------------------------------


\subsubsection{User-based Collaboration Filtering}
\label{subsubsec:user_based_cf}

User-based collaboration filtering computes missing user ratings by assuming that users with a similar preference, their \emph{peers}, will give ratings similar to their peers to unseen items.
The database is searched for users that are similar, called the \emph{neighborhood}, with respect to some similarity metric and their ratings are aggregated, for example by taking the mean the neighborhood.
We will use two similarity metrics in this study: the \emph{Jaccard similarity} \citep{Jaccard1912} and the \emph{Pearson correlation coefficient} \citep{Pearson1895}.

\begin{equation}
	  \mathrm{sim}_{\mathrm{Jaccard}}(A,B) = {{|A \cap B|}\over{|A \cup B|}} = {{|A \cap B|}\over{|A| + |B| - |A \cap B|}}
\end{equation}

The Jaccard similarity operates on itemsets, so in order to apply it to input vectors $\bm{x}$ and $\bm{y}$, these vectors are translated to their binary counterparts $\bm{x}^{*}$ and $\bm{y}^{*}$:

\begin{equation}
	\bm{x}^{*}_{i} =
	\begin{cases}
	    1,& \text{if } x_i > 0 \\
	    0,& \text{otherwise}
	\end{cases}
\end{equation}

The Jaccard similarity can then be calculated using this binary presentation instead.
For this, we first define four functions:

\begin{description}
	\setlength\itemsep{0em}
	\item [$M_{11}$] total number of positions where $x_i^{*}=y_i^*=1$
	\item [$M_{01}$] total number of positions where $x_i^*=0 \land y_i^*=0$
	\item [$M_{10}$] total number of positions where $x_i^*=1 \land y_i^*=0$
	\item [$M_{00}$] total number of positions where $x_i^*=y_i^*=0$
\end{description}

\begin{equation}
	\mathrm{sim}_{\mathrm{Jaccard}}=\frac{M_{11}}{M_{01} + M_{10} + M_{11}}
\end{equation}

This shows that the Jaccard similarity can be computed from the rating matrix itself.

Another similarity measure is the \emph{Pearson correlation coefficient}.

\begin{equation}
	\mathrm{sim}_{\mathrm{Pearson}}=\frac{\sum_{i \in I}(\bm{x}_{i}\bm{x})(\bm{y}_{i}\bm{y})}{(|I|-1)\mathrm{sd}(\bm{x})\mathrm{sd}(\bm{y})}
\end{equation}

It measures the linear correlation between two vectors of equal length, with a value in $[-1,1]$ where $-1$ denotes a total negative correlation and $1$ denotes total positive correlation.
We use this similarity measure for real-valued rating matrices.

In order to compute the neighborhood of a given user, the entire similarity matrix $S$($n \times n$) has to be computed first, which can be a limiting factor for this approach if the number of users is very large.
The user ratings are normalized by mean-centering the data (see \cref{subsubsec:user_ratings}).
Once the similarity matrix has been computed, the users most similar to the active user $u_a$ are extracted by selecting a group of fixed size $k$, the $k$-neighborhood $\mathcal{N}_{k}$.
The rating for an item by a user is computed by averaging the rating for this item in the neighborhood:

\begin{equation}
	r_{aj}=\frac{1}{|\mathcal{N}_{k}(a)|}\sum_{i\in\mathcal{N}(a)}r_{ij}
\end{equation}



%------------------------------------------------------------


\subsubsection{Item-based Collaboration Filtering}
\label{subsubsec:item_based_cf}

Item-based collaboration filtering \citep{Sarwar2001} is in many ways similar to user-based collaboration filtering.
This difference is that instead of computing ratings based on how similar users rated the item, the computed rating is based on ratings the user has given to similar items.
As an example we might consider a group of meals that are similar with respect to their ingredients, such as `Italian pastas with tomato sauce'.
Even though the ingredients of the recipes are unknown to the recommender system, users have often given similar ratings to items within this group, revealing item similarity through the preferences of the user group.

In order to decide which items are similar to one another, the similarity matrix $S$ ($m \times m$) is first computed.
Since the approach is essentially a $k$-nearest neighbor model applied to the columns, instead of the rows, of the rating matrix, only a pre-specified $k$ number of most similar items are stored in the model, meaning that $S$ can be a sparse matrix.
This greatly reduces the size of the model, improving the space and time complexity, be it at the cost of at the potential sacrifice of the system \citep{Sarwar2001}.

The same similarity metrics that apply to user-based collaborative filtering can also be used in this case, e.g. the Pearson correlation coefficient and the Jaccard similarity.
The latter assumes a binary rating matrix in which unrated items are assumed to be $0$.
Similar to user-based collaboration filtering, the set $\mathcal{S}(i)$ denotes the set with items similar to item $m_i$.
Let $\mathcal{R}(a)=\{l \mid r_{al} \neq {?}\}$ be the set of items that the active user has rated.
One way of predicting the rating of item $m_i$ is to take the average of the items that are similar to it and were rated by the user, i.e., to take the mean of ratings by $u_a$ to items in $\mathcal{S}(i) \cap \mathcal{R}(a)$.

\begin{equation}
	r_{ai}=\frac{1}{\sum_{j\in{\mathcal{S}(i)\cap \mathcal{R}(a)}}s_{ij}}\sum_{j\in{\mathcal{S}(i)\cap \mathcal{R}(a)}}s_{ij}r_{aj}
\end{equation}


%------------------------------------------------------------


\subsubsection{Association Rule-based Recommendation for Binary Data}
\label{subsubsec:association_recommendation}

If the rating matrix is a binary matrix, the rows and columns can be seen as sets.
The ratings can be thresholded in order to obtain a matrix in which a $1$ indicates that a user is likes a certain item.
Viewed in this way, association rule mining can be applied to this matrix to create a dependency model of items.
These items can be recipes in the case of a binarized rating matrix \emph{users} $\times$ \emph{recipes}, or ingredients, in the case of a \emph{recipe} $\times$ \emph{ingredient} matrix.
In both cases, the rating matrix is taken as input to the Apriori algorithm (\cref{alg:apriori}), treating the rows of the matrix as transactions, along with chosen support and confidence thresholds.
The itemset size is also limited in order to reduce the computational complexity of the recommendation step.
The result is a set of association rules $\mathcal{A}$.

To recommend an item to the active user $u_a$ a set of association rules $A \in \mathcal{A}$ is first searched for that have a precedent in the itemset $\mathcal{T}_a$ (the transaction) of the active user and a single-item antecedent, i.e., $A = \{X \rightarrow Y \mid X \subseteq \mathcal{T}_a, |\mathcal{Y}|=1\}$.
These rules are sorted according to an interestingness measure, such as confidence, after which the top-$N$ elements are recommended.